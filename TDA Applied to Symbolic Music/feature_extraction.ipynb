{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import converter, note, chord, instrument, meter, roman, stream, key, tempo\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from fractions import Fraction\n",
    "from scipy.stats import entropy\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "import traceback\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symbolic Feature Extraction for Topological Analysis of MIDI Data\n",
    "\n",
    "Here each MIDI file in the dataset is parsed to extract symbolic musical features such as pitch, duration, polyphony, key signature, and instrument information. These are compiled into a structured DataFrame for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_midi_features(midi_file, instrument_family_map=None):\n",
    "    try:\n",
    "        from music21 import converter, key, meter, instrument, note, chord, stream, tempo\n",
    "        import numpy as np\n",
    "\n",
    "        # Parse MIDI file\n",
    "        score = converter.parse(midi_file)\n",
    "        flat = score.flatten()\n",
    "\n",
    "        # === GLOBAL METADATA EXTRACTION ===\n",
    "        \n",
    "        # Key signature\n",
    "        key_signature = flat.analyze('key')\n",
    "        key_index = key_signature.tonic.pitchClass + (12 if key_signature.mode == 'minor' else 0)\n",
    "\n",
    "        # Time signature\n",
    "        time_signature = flat.recurse().getElementsByClass(meter.TimeSignature).first()\n",
    "        time_sig = str(time_signature.ratioString) if time_signature else '4/4'\n",
    "        time_sig_numerator = time_signature.numerator if time_signature else 4\n",
    "        bar_duration = time_signature.barDuration.quarterLength if time_signature else 4.0\n",
    "\n",
    "        # Tempo - optimized version\n",
    "        def extract_tempo(score, flat):\n",
    "            # Method 1: metronomeMarkBoundaries (most reliable)\n",
    "            try:\n",
    "                tempo_marks = score.metronomeMarkBoundaries()\n",
    "                if tempo_marks:\n",
    "                    return float(tempo_marks[0][2].number)\n",
    "            except (AttributeError, IndexError, TypeError):\n",
    "                pass\n",
    "\n",
    "            # Method 2: MetronomeMark in flattened score\n",
    "            try:\n",
    "                for mark in flat.recurse().getElementsByClass(tempo.MetronomeMark):\n",
    "                    if hasattr(mark, 'number') and mark.number:\n",
    "                        return float(mark.number)\n",
    "            except (AttributeError, TypeError):\n",
    "                pass\n",
    "\n",
    "            # Method 3: TempoIndication\n",
    "            try:\n",
    "                tempo_indication = flat.recurse().getElementsByClass('TempoIndication').first()\n",
    "                if tempo_indication and hasattr(tempo_indication, 'number') and tempo_indication.number:\n",
    "                    return float(tempo_indication.number)\n",
    "            except (AttributeError, TypeError):\n",
    "                pass\n",
    "\n",
    "            return 120.0  # Default value\n",
    "\n",
    "        tempo_bpm = extract_tempo(score, flat)\n",
    "\n",
    "        # === OPTIMIZATION: PRE-COMPUTE CONTEXTS ===\n",
    "        \n",
    "        # Group by offset to avoid recalculations\n",
    "        offset_dict = {}\n",
    "        element_contexts = {}  # Context cache\n",
    "        \n",
    "        for element in flat.notesAndRests:\n",
    "            offset_dict.setdefault(element.offset, []).append(element)\n",
    "            \n",
    "            # Pre-compute expensive contexts\n",
    "            instr_context = element.getContextByClass(instrument.Instrument)\n",
    "            track_context = element.getContextByClass(stream.Part)\n",
    "            key_context = element.getContextByClass(key.Key)\n",
    "            \n",
    "            element_contexts[id(element)] = {\n",
    "                'instrument': instr_context,\n",
    "                'track': track_context,\n",
    "                'key': key_context\n",
    "            }\n",
    "\n",
    "        def extract_instrument_info(element):\n",
    "            \"\"\"Optimized instrument info extraction\"\"\"\n",
    "            instr_name = \"Unknown\"\n",
    "            instr_family = \"Other\"\n",
    "            \n",
    "            instr = element_contexts[id(element)]['instrument']\n",
    "            if instr and hasattr(instr, 'midiProgram') and instr.midiProgram is not None:\n",
    "                try:\n",
    "                    instr_obj = instrument.instrumentFromMidiProgram(instr.midiProgram)\n",
    "                    instr_name = instr_obj.instrumentName if hasattr(instr_obj, 'instrumentName') else instr_name\n",
    "                    if instrument_family_map and instr_name in instrument_family_map:\n",
    "                        instr_family = instrument_family_map[instr_name]\n",
    "                except (AttributeError, ValueError, TypeError):\n",
    "                    pass\n",
    "            \n",
    "            return instr_name, instr_family\n",
    "\n",
    "        def get_track_name(element):\n",
    "            \"\"\"Optimized track name extraction\"\"\"\n",
    "            track_context = element_contexts[id(element)]['track']\n",
    "            if track_context and hasattr(track_context, 'partName') and track_context.partName:\n",
    "                return track_context.partName\n",
    "            return 'Unknown'\n",
    "\n",
    "        def get_local_key(element):\n",
    "            \"\"\"Optimized local key extraction\"\"\"\n",
    "            try:\n",
    "                local_key = element_contexts[id(element)]['key']\n",
    "                if local_key:\n",
    "                    return local_key.tonic.pitchClass + (12 if local_key.mode == 'minor' else 0)\n",
    "            except (AttributeError, TypeError):\n",
    "                pass\n",
    "            return key_index\n",
    "\n",
    "        # === OPTIMIZED METRIC CALCULATIONS ===\n",
    "        \n",
    "        def calculate_metric_weight(beat_position, time_sig_numerator):\n",
    "            \"\"\"Calculate metric weight based on position in measure\"\"\"\n",
    "            beat_int = int(beat_position)\n",
    "            \n",
    "            # Weights for common time signatures\n",
    "            if time_sig_numerator == 4:\n",
    "                weights = {1: 1.0, 2: 0.4, 3: 0.6, 4: 0.2}\n",
    "            elif time_sig_numerator == 3:\n",
    "                weights = {1: 1.0, 2: 0.4, 3: 0.6}\n",
    "            elif time_sig_numerator == 2:\n",
    "                weights = {1: 1.0, 2: 0.5}\n",
    "            else:\n",
    "                # Generic: strong first beat, others weaker\n",
    "                weights = {1: 1.0}\n",
    "                for i in range(2, time_sig_numerator + 1):\n",
    "                    weights[i] = 0.4 if i % 2 == 0 else 0.6\n",
    "            \n",
    "            return weights.get(beat_int, 0.3)\n",
    "\n",
    "        # === FEATURE EXTRACTION ===\n",
    "        \n",
    "        features = []\n",
    "        previous_pitch = None\n",
    "        \n",
    "        for offset, simultaneous_elements in sorted(offset_dict.items()):\n",
    "            polyphony = len(simultaneous_elements)\n",
    "\n",
    "            for element in simultaneous_elements:\n",
    "                # Extract pre-computed contexts\n",
    "                instr_name, instr_family = extract_instrument_info(element)\n",
    "                track_name = get_track_name(element)\n",
    "                local_key_index = get_local_key(element)\n",
    "                \n",
    "                # Metric calculations\n",
    "                beat_position = element.beat if hasattr(element, 'beat') else 1.0\n",
    "                beat_fraction = beat_position / time_sig_numerator\n",
    "                metric_weight = calculate_metric_weight(beat_position, time_sig_numerator)\n",
    "                measure_number = element.measureNumber if hasattr(element, 'measureNumber') and element.measureNumber is not None else 0\n",
    "                articulation_ratio = float(element.quarterLength) / bar_duration\n",
    "\n",
    "                # Common features\n",
    "                common_features = {\n",
    "                    'onset': float(offset),\n",
    "                    'duration': float(element.quarterLength),\n",
    "                    'polyphony': polyphony,\n",
    "                    'key': key_index,\n",
    "                    'local_key': local_key_index,\n",
    "                    'time_signature': time_sig,\n",
    "                    'tempo': tempo_bpm,\n",
    "                    'measure': measure_number,\n",
    "                    'beat_position': beat_position,\n",
    "                    'beat_fraction': beat_fraction,\n",
    "                    'metric_weight': metric_weight,\n",
    "                    'articulation_ratio': articulation_ratio,\n",
    "                    'instrument': instr_name,\n",
    "                    'instrument_family': instr_family,\n",
    "                    'track': track_name,\n",
    "                }\n",
    "\n",
    "                # Element-specific processing\n",
    "                if isinstance(element, note.Note):\n",
    "                    pitch = element.pitch.midi\n",
    "                    pitch_class = element.pitch.pitchClass\n",
    "                    pitch_octave = element.pitch.octave\n",
    "                    velocity = element.volume.velocity if (element.volume and \n",
    "                                                         hasattr(element.volume, 'velocity') and \n",
    "                                                         element.volume.velocity is not None) else -1\n",
    "                    interval_to_prev = abs(pitch - previous_pitch) if previous_pitch is not None else 0\n",
    "                    previous_pitch = pitch\n",
    "\n",
    "                    features.append({\n",
    "                        **common_features,\n",
    "                        'pitch': pitch,\n",
    "                        'pitch_class': pitch_class,\n",
    "                        'pitch_octave': pitch_octave,\n",
    "                        'interval_to_prev': interval_to_prev,\n",
    "                        'is_chord_tone': 0,\n",
    "                        'velocity': velocity,\n",
    "                        'is_rest': 0\n",
    "                    })\n",
    "\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    duration = float(element.quarterLength)\n",
    "                    velocity = element.volume.velocity if (element.volume and \n",
    "                                                         hasattr(element.volume, 'velocity') and \n",
    "                                                         element.volume.velocity is not None) else -1\n",
    "\n",
    "                    # Sort pitches for consistency\n",
    "                    pitches = sorted([p.midi for p in element.pitches])\n",
    "                    \n",
    "                    for pitch in pitches:\n",
    "                        pitch_class = pitch % 12\n",
    "                        pitch_octave = pitch // 12\n",
    "                        interval_to_prev = abs(pitch - previous_pitch) if previous_pitch is not None else 0\n",
    "                        previous_pitch = pitch\n",
    "\n",
    "                        features.append({\n",
    "                            **common_features,\n",
    "                            'pitch': pitch,\n",
    "                            'pitch_class': pitch_class,\n",
    "                            'pitch_octave': pitch_octave,\n",
    "                            'interval_to_prev': interval_to_prev,\n",
    "                            'is_chord_tone': 1,\n",
    "                            'velocity': velocity,\n",
    "                            'is_rest': 0\n",
    "                        })\n",
    "\n",
    "                elif isinstance(element, note.Rest):\n",
    "                    features.append({\n",
    "                        **common_features,\n",
    "                        'pitch': -1,\n",
    "                        'pitch_class': -1,\n",
    "                        'pitch_octave': -1,\n",
    "                        'interval_to_prev': 0,\n",
    "                        'is_chord_tone': 0,\n",
    "                        'velocity': -1,\n",
    "                        'is_rest': 1\n",
    "                    })\n",
    "\n",
    "        return features\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Could not parse {midi_file}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()  # For detailed debugging\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add instrument family to each event for higher-level grouping (e.g., strings, winds, percussion)\n",
    "# This enables downstream analysis of timbral or orchestration patterns across genres or pieces\n",
    "\n",
    "instrument_family_map = {\n",
    "    # Keyboard\n",
    "    'Piano': 'Keyboard',\n",
    "    'Electric Piano': 'Electronic',\n",
    "    'Celesta': 'Keyboard',\n",
    "    'Organ': 'Keyboard',\n",
    "    'Electric Organ': 'Keyboard',\n",
    "    'Harpsichord': 'Keyboard',\n",
    "\n",
    "    # Guitar\n",
    "    'Acoustic Guitar': 'Guitar',\n",
    "    'Electric Guitar': 'Guitar',\n",
    "\n",
    "    # Bass\n",
    "    'Acoustic Bass': 'Bass',\n",
    "    'Electric Bass': 'Bass',\n",
    "    'Fretless Bass': 'Bass',\n",
    "    'Contrabass': 'Bass',\n",
    "\n",
    "    # Strings\n",
    "    'Violoncello': 'Strings',\n",
    "    'Violin': 'Strings',\n",
    "    'Viola': 'Strings',\n",
    "    'Double Bass': 'Strings',\n",
    "    'StringInstrument': 'Strings',\n",
    "\n",
    "    # Brass\n",
    "    'Trumpet': 'Brass',\n",
    "    'Trombone': 'Brass',\n",
    "    'French Horn': 'Brass',\n",
    "    'Tuba': 'Brass',\n",
    "\n",
    "    # Woodwind\n",
    "    'Clarinet': 'Woodwind',\n",
    "    'Bassoon': 'Woodwind',\n",
    "    'Recorder': 'Woodwind',\n",
    "    'Piccolo': 'Woodwind',\n",
    "    'Flute': 'Woodwind',\n",
    "    'Whistle': 'Woodwind',\n",
    "\n",
    "    # Percussion\n",
    "    'Timpani': 'Percussion',\n",
    "    'Taiko': 'Percussion',\n",
    "    'Marimba': 'Percussion',\n",
    "    'Glockenspiel': 'Percussion',\n",
    "    'Drums': 'Percussion',\n",
    "\n",
    "    # Voice\n",
    "    'Voice': 'Voice',\n",
    "    'Choir': 'Voice',\n",
    "    'Vocals': 'Voice',\n",
    "    'Background Vocals': 'Voice',\n",
    "\n",
    "    # Electronic\n",
    "    'Sampler': 'Electronic',\n",
    "    'Synthesizer': 'Electronic',\n",
    "\n",
    "    # Other / Catch-all\n",
    "    'Bagpipes': 'Other',\n",
    "    'Ocarina': 'Other',\n",
    "    'Unknown': 'Other',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging for better error tracking\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('midi_extraction.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "def process_single_file(file_path: str, genre: str, filename: str, instrument_family_map: Optional[Dict] = None) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Process a single MIDI file and return features with metadata.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the MIDI file\n",
    "        genre: Genre label for the file\n",
    "        filename: Name of the file\n",
    "        instrument_family_map: Optional mapping of instruments to families\n",
    "    \n",
    "    Returns:\n",
    "        List[Dict]: Features with genre and filename metadata\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Import here to ensure availability in each thread\n",
    "        from music21 import converter, key, meter, instrument, note, chord, stream, tempo\n",
    "        \n",
    "        # Extract features using the optimized function\n",
    "        features = get_midi_features(file_path, instrument_family_map)\n",
    "        \n",
    "        # Add metadata to each feature\n",
    "        for feature in features:\n",
    "            feature['genre'] = genre\n",
    "            feature['filename'] = filename\n",
    "            \n",
    "        logging.info(f\"Successfully processed {filename} ({genre}): {len(features)} features extracted\")\n",
    "        return features\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing {filename} ({genre}): {str(e)}\")\n",
    "        logging.debug(traceback.format_exc())\n",
    "        return []\n",
    "\n",
    "def get_midi_files_info(root_path: str) -> List[tuple]:\n",
    "    \"\"\"\n",
    "    Scan directory structure and collect MIDI file information.\n",
    "    \n",
    "    Args:\n",
    "        root_path: Path to root directory containing genre subfolders\n",
    "        \n",
    "    Returns:\n",
    "        List[tuple]: List of (file_path, genre, filename) tuples\n",
    "    \"\"\"\n",
    "    midi_files_info = []\n",
    "    root_path = Path(root_path)\n",
    "    \n",
    "    if not root_path.exists():\n",
    "        raise FileNotFoundError(f\"Root path does not exist: {root_path}\")\n",
    "    \n",
    "    # Supported MIDI extensions\n",
    "    midi_extensions = {'.mid', '.midi', '.MID', '.MIDI'}\n",
    "    \n",
    "    for genre_dir in root_path.iterdir():\n",
    "        if not genre_dir.is_dir():\n",
    "            continue\n",
    "            \n",
    "        genre_name = genre_dir.name\n",
    "        midi_count = 0\n",
    "        \n",
    "        for file_path in genre_dir.iterdir():\n",
    "            if file_path.suffix in midi_extensions:\n",
    "                midi_files_info.append((\n",
    "                    str(file_path),\n",
    "                    genre_name,\n",
    "                    file_path.name\n",
    "                ))\n",
    "                midi_count += 1\n",
    "        \n",
    "        logging.info(f\"Found {midi_count} MIDI files in genre: {genre_name}\")\n",
    "    \n",
    "    logging.info(f\"Total MIDI files found: {len(midi_files_info)}\")\n",
    "    return midi_files_info\n",
    "\n",
    "def extract_features_threaded(\n",
    "    root_path: str,\n",
    "    instrument_family_map: Optional[Dict] = None,\n",
    "    max_workers: Optional[int] = None,\n",
    "    use_threading: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract features from all MIDI files using thread-based parallelism.\n",
    "    \n",
    "    Args:\n",
    "        root_path: Path to root directory containing genre subfolders\n",
    "        instrument_family_map: Optional mapping of instruments to families\n",
    "        max_workers: Number of parallel workers (None for auto-detection)\n",
    "        use_threading: Whether to use threading (vs single-threaded)\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing all extracted features\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get all MIDI files information\n",
    "    midi_files_info = get_midi_files_info(root_path)\n",
    "    \n",
    "    if not midi_files_info:\n",
    "        logging.warning(\"No MIDI files found!\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    all_features = []\n",
    "    \n",
    "    if use_threading and len(midi_files_info) > 1:\n",
    "        # Determine optimal number of workers (I/O bound task, can use more threads)\n",
    "        if max_workers is None:\n",
    "            max_workers = min(16, len(midi_files_info))  # Cap at 16 threads\n",
    "        \n",
    "        logging.info(f\"Using {max_workers} parallel threads for feature extraction\")\n",
    "        \n",
    "        # Use ThreadPoolExecutor for I/O-bound tasks (MIDI file reading)\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            # Submit all tasks\n",
    "            future_to_info = {\n",
    "                executor.submit(process_single_file, file_path, genre, filename, instrument_family_map): (file_path, genre, filename)\n",
    "                for file_path, genre, filename in midi_files_info\n",
    "            }\n",
    "            \n",
    "            # Collect results with progress bar\n",
    "            with tqdm(total=len(midi_files_info), desc=\"Processing MIDI files\") as pbar:\n",
    "                for future in as_completed(future_to_info):\n",
    "                    try:\n",
    "                        features = future.result()\n",
    "                        if features:  # Only extend if features were extracted\n",
    "                            all_features.extend(features)\n",
    "                        pbar.update(1)\n",
    "                    except Exception as e:\n",
    "                        file_info = future_to_info[future]\n",
    "                        logging.error(f\"Failed to process {file_info[2]}: {str(e)}\")\n",
    "                        pbar.update(1)\n",
    "    else:\n",
    "        # Single-threaded processing\n",
    "        logging.info(\"Using single-threaded processing\")\n",
    "        for file_path, genre, filename in tqdm(midi_files_info, desc=\"Processing MIDI files\"):\n",
    "            features = process_single_file(file_path, genre, filename, instrument_family_map)\n",
    "            if features:  # Only extend if features were extracted\n",
    "                all_features.extend(features)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    if all_features:\n",
    "        df = pd.DataFrame(all_features)\n",
    "        logging.info(f\"Created DataFrame with {len(df)} feature rows from {len(midi_files_info)} files\")\n",
    "        \n",
    "        # Basic data validation\n",
    "        validate_dataframe(df)\n",
    "        \n",
    "        return df\n",
    "    else:\n",
    "        logging.warning(\"No features extracted!\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def extract_features_sequential(\n",
    "    root_path: str,\n",
    "    instrument_family_map: Optional[Dict] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Sequential version that closely mirrors your original code but with improvements.\n",
    "    \n",
    "    Args:\n",
    "        root_path: Path to root directory containing genre subfolders\n",
    "        instrument_family_map: Optional mapping of instruments to families\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing all extracted features\n",
    "    \"\"\"\n",
    "    \n",
    "    logging.info(\"=== Sequential MIDI Feature Extraction ===\")\n",
    "    logging.info(f\"Root path: {root_path}\")\n",
    "    \n",
    "    # Initialize empty list to collect features (like your original code)\n",
    "    all_features = []\n",
    "    \n",
    "    # Get list of genres and files first\n",
    "    root_path = Path(root_path)\n",
    "    if not root_path.exists():\n",
    "        raise FileNotFoundError(f\"Root path does not exist: {root_path}\")\n",
    "    \n",
    "    midi_extensions = {'.mid', '.midi', '.MID', '.MIDI'}\n",
    "    total_files = 0\n",
    "    processed_files = 0\n",
    "    failed_files = 0\n",
    "    \n",
    "    # Count total files first for progress tracking\n",
    "    for genre_dir in root_path.iterdir():\n",
    "        if genre_dir.is_dir():\n",
    "            total_files += len([f for f in genre_dir.iterdir() if f.suffix in midi_extensions])\n",
    "    \n",
    "    logging.info(f\"Found {total_files} MIDI files to process\")\n",
    "    \n",
    "    # Process each genre subfolder (exactly like your original code structure)\n",
    "    with tqdm(total=total_files, desc=\"Processing MIDI files\") as pbar:\n",
    "        for genre_dir in root_path.iterdir():\n",
    "            if not genre_dir.is_dir():\n",
    "                continue  # Skip non-directory files\n",
    "            \n",
    "            genre = genre_dir.name\n",
    "            genre_file_count = 0\n",
    "            \n",
    "            # Process each MIDI file within the current genre folder\n",
    "            for file_path in genre_dir.iterdir():\n",
    "                if file_path.suffix not in midi_extensions:\n",
    "                    continue  # Ignore non-MIDI files\n",
    "                \n",
    "                filename = file_path.name\n",
    "                \n",
    "                try:\n",
    "                    # Extract features from current MIDI file (your original logic)\n",
    "                    features = get_midi_features(str(file_path), instrument_family_map)\n",
    "                    \n",
    "                    if features:\n",
    "                        # Add genre and filename metadata to each feature (your original logic)\n",
    "                        for feature in features:\n",
    "                            feature['genre'] = genre\n",
    "                            feature['filename'] = filename\n",
    "                            all_features.append(feature)\n",
    "                        \n",
    "                        processed_files += 1\n",
    "                        genre_file_count += 1\n",
    "                    else:\n",
    "                        logging.warning(f\"No features extracted from {filename}\")\n",
    "                        failed_files += 1\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error processing {filename} ({genre}): {str(e)}\")\n",
    "                    failed_files += 1\n",
    "                \n",
    "                pbar.update(1)\n",
    "            \n",
    "            logging.info(f\"Processed {genre_file_count} files from genre: {genre}\")\n",
    "    \n",
    "    # Create DataFrame (like your original code)\n",
    "    if all_features:\n",
    "        df = pd.DataFrame(all_features)\n",
    "        logging.info(f\"Successfully created DataFrame with {len(df)} feature rows\")\n",
    "        logging.info(f\"Files processed: {processed_files}/{total_files} (Failed: {failed_files})\")\n",
    "        \n",
    "        # Basic validation\n",
    "        validate_dataframe(df)\n",
    "        \n",
    "        return df\n",
    "    else:\n",
    "        logging.error(\"No features extracted from any files!\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def validate_dataframe(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Perform basic validation on the extracted features DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame to validate\n",
    "    \"\"\"\n",
    "    logging.info(\"=== DataFrame Validation ===\")\n",
    "    logging.info(f\"Shape: {df.shape}\")\n",
    "    logging.info(f\"Genres: {df['genre'].nunique()} unique ({sorted(df['genre'].unique())})\")\n",
    "    logging.info(f\"Files processed: {df['filename'].nunique()}\")\n",
    "    \n",
    "    # Check for missing values in critical columns\n",
    "    critical_columns = ['pitch', 'onset', 'duration', 'genre', 'filename']\n",
    "    for col in critical_columns:\n",
    "        if col in df.columns:\n",
    "            missing_count = df[col].isnull().sum()\n",
    "            if missing_count > 0:\n",
    "                logging.warning(f\"Column '{col}' has {missing_count} missing values\")\n",
    "    \n",
    "    # Check for potential data quality issues\n",
    "    if 'pitch' in df.columns:\n",
    "        pitch_range = (df[df['pitch'] != -1]['pitch'].min(), df[df['pitch'] != -1]['pitch'].max())\n",
    "        logging.info(f\"Pitch range (excluding rests): {pitch_range}\")\n",
    "        if pitch_range[0] < 0 or pitch_range[1] > 127:\n",
    "            logging.warning(f\"Unusual pitch range detected: {pitch_range}\")\n",
    "    \n",
    "    if 'duration' in df.columns:\n",
    "        negative_durations = (df['duration'] <= 0).sum()\n",
    "        if negative_durations > 0:\n",
    "            logging.warning(f\"Found {negative_durations} non-positive durations\")\n",
    "        else:\n",
    "            duration_range = (df['duration'].min(), df['duration'].max())\n",
    "            logging.info(f\"Duration range: {duration_range}\")\n",
    "\n",
    "def extract_features_with_summary(\n",
    "    root_path: str = 'data',\n",
    "    instrument_family_map: Optional[Dict] = None,\n",
    "    method: str = 'sequential',  # 'sequential', 'threaded'\n",
    "    max_workers: Optional[int] = None,\n",
    "    save_excel: bool = True,\n",
    "    excel_filename: str = 'datasets/midi_features.xlsx'\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Complete pipeline for feature extraction with summary statistics.\n",
    "    \n",
    "    Args:\n",
    "        root_path: Path to root directory containing genre subfolders\n",
    "        instrument_family_map: Optional mapping of instruments to families\n",
    "        method: Extraction method ('sequential' or 'threaded')\n",
    "        max_workers: Number of parallel workers (for threaded method)\n",
    "        save_excel: Whether to save the DataFrame as Excel\n",
    "        excel_filename: Output Excel filename\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Extracted features DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    logging.info(\"=== MIDI Feature Extraction Pipeline ===\")\n",
    "    logging.info(f\"Root path: {root_path}\")\n",
    "    logging.info(f\"Method: {method}\")\n",
    "    \n",
    "    # Extract features based on chosen method\n",
    "    if method == 'sequential':\n",
    "        df = extract_features_sequential(\n",
    "            root_path=root_path,\n",
    "            instrument_family_map=instrument_family_map\n",
    "        )\n",
    "    elif method == 'threaded':\n",
    "        df = extract_features_threaded(\n",
    "            root_path=root_path,\n",
    "            instrument_family_map=instrument_family_map,\n",
    "            max_workers=max_workers\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}. Use 'sequential' or 'threaded'\")\n",
    "    \n",
    "    if df.empty:\n",
    "        logging.error(\"No features extracted. Check your MIDI files and paths.\")\n",
    "        return df\n",
    "    \n",
    "    # Generate summary statistics\n",
    "    logging.info(\"=== Summary Statistics ===\")\n",
    "    genre_counts = df['genre'].value_counts()\n",
    "    print(f\"\\nGenre distribution:\")\n",
    "    for genre, count in genre_counts.items():\n",
    "        print(f\"  {genre}: {count} features\")\n",
    "    \n",
    "    print(f\"\\nFiles per genre:\")\n",
    "    files_per_genre = df.groupby('genre')['filename'].nunique()\n",
    "    for genre, file_count in files_per_genre.items():\n",
    "        feature_count = genre_counts[genre]\n",
    "        print(f\"  {genre}: {file_count} files, avg {feature_count/file_count:.1f} features/file\")\n",
    "    \n",
    "    print(f\"\\nNumeric features summary:\")\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    print(df[numeric_cols].describe().round(2))\n",
    "    \n",
    "    # Save to excel if requested\n",
    "    if save_excel:\n",
    "        df.to_excel(excel_filename, index=False)\n",
    "        logging.info(f\"DataFrame saved to {excel_filename}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-06 14:54:13,175 - INFO - === MIDI Feature Extraction Pipeline ===\n",
      "2025-08-06 14:54:13,177 - INFO - Root path: data\n",
      "2025-08-06 14:54:13,178 - INFO - Method: sequential\n",
      "2025-08-06 14:54:13,179 - INFO - === Sequential MIDI Feature Extraction ===\n",
      "2025-08-06 14:54:13,179 - INFO - Root path: data\n",
      "2025-08-06 14:54:13,183 - INFO - Found 45 MIDI files to process\n",
      "Processing MIDI files:   7%|▋         | 3/45 [00:17<03:49,  5.47s/it]2025-08-06 14:54:30,374 - INFO - Processed 3 files from genre: pop\n",
      "Processing MIDI files:  13%|█▎        | 6/45 [00:30<02:48,  4.33s/it]2025-08-06 14:54:43,232 - INFO - Processed 3 files from genre: heavy_metal\n",
      "Processing MIDI files:  20%|██        | 9/45 [00:46<03:02,  5.06s/it]2025-08-06 14:55:00,074 - INFO - Processed 3 files from genre: disco\n",
      "Processing MIDI files:  27%|██▋       | 12/45 [00:57<02:05,  3.82s/it]2025-08-06 14:55:10,577 - INFO - Processed 3 files from genre: blues\n",
      "Processing MIDI files:  33%|███▎      | 15/45 [01:08<01:50,  3.67s/it]2025-08-06 14:55:21,399 - INFO - Processed 3 files from genre: alternative_rock\n",
      "Processing MIDI files:  40%|████      | 18/45 [01:25<02:14,  4.99s/it]2025-08-06 14:55:38,716 - INFO - Processed 3 files from genre: rnb\n",
      "Processing MIDI files:  47%|████▋     | 21/45 [01:45<02:25,  6.08s/it]2025-08-06 14:55:58,616 - INFO - Processed 3 files from genre: reggae\n",
      "Processing MIDI files:  53%|█████▎    | 24/45 [01:55<01:38,  4.69s/it]2025-08-06 14:56:09,145 - INFO - Processed 3 files from genre: classical\n",
      "Processing MIDI files:  60%|██████    | 27/45 [02:05<01:07,  3.75s/it]2025-08-06 14:56:19,198 - INFO - Processed 3 files from genre: rock\n",
      "Processing MIDI files:  67%|██████▋   | 30/45 [02:25<01:20,  5.39s/it]2025-08-06 14:56:39,146 - INFO - Processed 3 files from genre: new_age\n",
      "Processing MIDI files:  73%|███████▎  | 33/45 [02:40<01:02,  5.20s/it]2025-08-06 14:56:53,934 - INFO - Processed 3 files from genre: dance\n",
      "Processing MIDI files:  80%|████████  | 36/45 [02:57<00:49,  5.50s/it]2025-08-06 14:57:11,119 - INFO - Processed 3 files from genre: soul\n",
      "Processing MIDI files:  87%|████████▋ | 39/45 [03:15<00:33,  5.60s/it]2025-08-06 14:57:29,203 - INFO - Processed 3 files from genre: country\n",
      "Processing MIDI files:  93%|█████████▎| 42/45 [03:36<00:19,  6.50s/it]2025-08-06 14:57:49,642 - INFO - Processed 3 files from genre: rap\n",
      "Processing MIDI files: 100%|██████████| 45/45 [03:52<00:00,  5.24s/it]2025-08-06 14:58:05,641 - INFO - Processed 3 files from genre: jazz\n",
      "Processing MIDI files: 100%|██████████| 45/45 [03:52<00:00,  5.17s/it]\n",
      "2025-08-06 14:58:06,172 - INFO - Successfully created DataFrame with 223830 feature rows\n",
      "2025-08-06 14:58:06,173 - INFO - Files processed: 45/45 (Failed: 0)\n",
      "2025-08-06 14:58:06,173 - INFO - === DataFrame Validation ===\n",
      "2025-08-06 14:58:06,173 - INFO - Shape: (223830, 24)\n",
      "2025-08-06 14:58:06,189 - INFO - Genres: 15 unique (['alternative_rock', 'blues', 'classical', 'country', 'dance', 'disco', 'heavy_metal', 'jazz', 'new_age', 'pop', 'rap', 'reggae', 'rnb', 'rock', 'soul'])\n",
      "2025-08-06 14:58:06,196 - INFO - Files processed: 45\n",
      "2025-08-06 14:58:06,244 - INFO - Pitch range (excluding rests): (np.int64(21), np.int64(108))\n",
      "2025-08-06 14:58:06,245 - INFO - Duration range: (np.float64(0.08333333333333333), np.float64(28.25))\n",
      "2025-08-06 14:58:06,350 - INFO - === Summary Statistics ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Genre distribution:\n",
      "  reggae: 22552 features\n",
      "  rap: 20989 features\n",
      "  country: 20690 features\n",
      "  soul: 18681 features\n",
      "  rnb: 18310 features\n",
      "  new_age: 17543 features\n",
      "  pop: 17299 features\n",
      "  jazz: 15127 features\n",
      "  disco: 13343 features\n",
      "  heavy_metal: 10838 features\n",
      "  blues: 10184 features\n",
      "  classical: 10173 features\n",
      "  dance: 9658 features\n",
      "  rock: 9565 features\n",
      "  alternative_rock: 8878 features\n",
      "\n",
      "Files per genre:\n",
      "  alternative_rock: 3 files, avg 2959.3 features/file\n",
      "  blues: 3 files, avg 3394.7 features/file\n",
      "  classical: 3 files, avg 3391.0 features/file\n",
      "  country: 3 files, avg 6896.7 features/file\n",
      "  dance: 3 files, avg 3219.3 features/file\n",
      "  disco: 3 files, avg 4447.7 features/file\n",
      "  heavy_metal: 3 files, avg 3612.7 features/file\n",
      "  jazz: 3 files, avg 5042.3 features/file\n",
      "  new_age: 3 files, avg 5847.7 features/file\n",
      "  pop: 3 files, avg 5766.3 features/file\n",
      "  rap: 3 files, avg 6996.3 features/file\n",
      "  reggae: 3 files, avg 7517.3 features/file\n",
      "  rnb: 3 files, avg 6103.3 features/file\n",
      "  rock: 3 files, avg 3188.3 features/file\n",
      "  soul: 3 files, avg 6227.0 features/file\n",
      "\n",
      "Numeric features summary:\n",
      "           onset   duration  polyphony        key  local_key      tempo  \\\n",
      "count  223830.00  223830.00  223830.00  223830.00  223830.00  223830.00   \n",
      "mean      224.98       0.79       5.15      10.75       7.94     118.87   \n",
      "std       143.28       0.99       3.90       7.81       7.79      27.83   \n",
      "min         0.00       0.08       1.00       0.00       0.00      78.00   \n",
      "25%       112.00       0.25       3.00       3.00       0.00     100.00   \n",
      "50%       209.25       0.50       4.00      11.00       5.00     118.00   \n",
      "75%       314.25       0.75       6.00      19.00      14.00     125.00   \n",
      "max       755.83      28.25      28.00      23.00      23.00     208.00   \n",
      "\n",
      "         measure  metric_weight  articulation_ratio      pitch  pitch_class  \\\n",
      "count  223830.00      223830.00           223830.00  223830.00    223830.00   \n",
      "mean       56.61           0.60                0.20      39.34         3.45   \n",
      "std        35.34           0.31                0.24      30.14         4.17   \n",
      "min         1.00           0.20                0.01      -1.00        -1.00   \n",
      "25%        29.00           0.40                0.06      -1.00        -1.00   \n",
      "50%        53.00           0.60                0.12      52.00         3.00   \n",
      "75%        79.00           1.00                0.19      65.00         7.00   \n",
      "max       188.00           1.00                4.71     108.00        11.00   \n",
      "\n",
      "       pitch_octave  interval_to_prev  is_chord_tone   velocity    is_rest  \n",
      "count     223830.00         223830.00      223830.00  223830.00  223830.00  \n",
      "mean           2.41              7.55           0.42      62.01       0.33  \n",
      "std            2.63             10.80           0.49      48.03       0.47  \n",
      "min           -1.00              0.00           0.00      -1.00       0.00  \n",
      "25%           -1.00              0.00           0.00      -1.00       0.00  \n",
      "50%            3.00              3.00           0.00      80.00       0.00  \n",
      "75%            5.00             11.00           1.00     100.00       1.00  \n",
      "max            9.00             71.00           1.00     127.00       1.00  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-06 14:58:07,381 - INFO - DataFrame saved to midi_features.csv\n"
     ]
    }
   ],
   "source": [
    "df = extract_features_with_summary(\n",
    "    root_path='MIDI_files',\n",
    "    instrument_family_map=instrument_family_map,\n",
    "    method='sequential'  # Sûr et stable\n",
    ")\n",
    "df.to_excel('datasets/midi_features.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
